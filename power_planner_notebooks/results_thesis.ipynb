{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import networkx as nx\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "from csv import writer\n",
    "import pickle\n",
    "import seaborn as sb\n",
    "from power_planner import graphs\n",
    "from power_planner.utils.utils import get_distance_surface, rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/belgium_data_1_2.dat\", \"rb\") as infile:\n",
    "    (belgium_inst, belgium_edge_inst, belgium_inst_corr, belgium_config) = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run once for each instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impl_graph_de = graphs.ImplicitLG(belgium_inst, belgium_inst_corr, edge_instance=belgium_edge_inst)\n",
    "path_impl_de, path_costs_impl_belgium, cost_sum_impl_belgium =  impl_graph_de.single_sp(**vars(belgium_config.graph))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make images with one path in each instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counter=1\n",
    "for name, path_impl, graph in zip([\"belgium_\", \"de_\", \"ch_\"],[path_impl_belgium, path_impl_de, path_impl_ch], [impl_graph_belgium, impl_graph_de, impl_graph_ch]):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    # plt.subplot(1,3,counter)\n",
    "    path_impl = np.array(path_impl)\n",
    "    # path_window = np.array(path_window)\n",
    "    plt.imshow(np.swapaxes(graph.instance,1,0)) # [20:,20:]\n",
    "    plt.scatter(path_impl[:,0], path_impl[:,1], label=\"Optimal path (Cost: 13.8)\",c=\"red\", s=3)\n",
    "    # plt.scatter(path_window[:,1]-50, path_window[:,0]-50, label=\"Forced through window (14.2)\", s=100)\n",
    "    plt.axis(\"off\")\n",
    "    # plt.legend(loc=\"upper left\",framealpha=1)\n",
    "    counter +=1\n",
    "# plt.tight_layout()\n",
    "    plt.savefig(\"../../figure/\"+name+\"_all_instances.pdf\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct table about instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belgium_inst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "739 * 1300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_x = np.where(np.any(belgium_inst_corr!=0, axis=1))[0][0]\n",
    "end_x = np.where(np.any(belgium_inst_corr!=0, axis=1))[0][-1]\n",
    "start_y = np.where(np.any(belgium_inst_corr!=0, axis=0))[0][0]\n",
    "end_y = np.where(np.any(belgium_inst_corr!=0, axis=0))[0][-1]\n",
    "stripped_inst = belgium_inst[:, start_x:end_x, start_y:end_y]\n",
    "stripped_corr = belgium_inst_corr[start_x:end_x, start_y:end_y]\n",
    "print(stripped_inst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(stripped_corr>0)[0]), len(np.where(stripped_corr>0)[0])/(stripped_corr.shape[0]* stripped_corr.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = graphs.ImplicitLG(belgium_inst, belgium_inst_corr, edge_instance=belgium_edge_inst)\n",
    "g.set_shift(belgium_config.graph.start_inds, belgium_config.graph.dest_inds, **vars(belgium_config.graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(stripped_corr>0)[0]) * len(g.shifts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(g.shifts), belgium_config.graph.pylon_dist_min, belgium_config.graph.pylon_dist_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run for different graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impl_graph = graphs.ImplicitLG(belgium_inst, belgium_inst_corr, edge_instance=belgium_edge_inst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "belgium_config.graph.ANGLE_WEIGHT=0.3\n",
    "path_impl, path_costs_impl, cost_sum_impl =  impl_graph.single_sp(**vars(belgium_config.graph))\n",
    "print(time.time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg_graph = graphs.WeightedGraph(belgium_inst, belgium_inst_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "path_wg, path_costs_wg, cost_sum_wg = wg_graph.single_sp(**vars(belgium_config.graph))\n",
    "print(time.time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_graph = graphs.LineGraph(belgium_inst, belgium_inst_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "out_impl = lg_graph.single_sp(**vars(belgium_config.graph))\n",
    "print(time.time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_impl, path_costs_impl, cost_sum_impl =  impl_graph.sp_trees(**vars(belgium_config.graph))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make plot for Alternative path (force through window figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from power_planner.alternative_paths import AlternativePaths\n",
    "alt = AlternativePaths(impl_graph)\n",
    "path_window, path_window_cost, cost_sum_window = alt.path_through_window(\n",
    "    150, 200, 250, 300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_sum_window, cost_sum_impl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_impl = np.array(path_impl)\n",
    "path_window = np.array(path_window)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(impl_graph.instance[50:,50:])# np.swapaxes( ,1,0))\n",
    "plt.scatter(path_impl[:,1]-50, path_impl[:,0]-50, label=\"Optimal path (Cost: 13.8)\", s=100)\n",
    "plt.scatter(path_window[:,1]-50, path_window[:,0]-50, label=\"Forced through window (14.2)\", s=100)\n",
    "plt.axis(\"off\")\n",
    "plt.legend(loc=\"upper left\",framealpha=1)\n",
    "plt.savefig(\"../../figure/path_through_window.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline figure: take random data and run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_instance = np.random.rand(4, 50,50)\n",
    "config = belgium_config\n",
    "start_start = np.array([4,4])\n",
    "start_dest = np.array([46,46])\n",
    "PYLON_DIST_MIN = 6\n",
    "PYLON_DIST_MAX = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scales = [4, 2,1]\n",
    "dist = [0,5, 5]\n",
    "corr = np.ones((int(random_instance.shape[1]/scales[0]), int(random_instance.shape[2]/scales[0])))\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "for i in range(len(scales)):\n",
    "    instance = np.array([rescale(img_i, scales[i]) for img_i in random_instance])\n",
    "    print(instance.shape)\n",
    "    \n",
    "    if dist[i]>0:\n",
    "\n",
    "        # upscale path\n",
    "        path = (path * scales[i-1]/scales[i]).astype(int)\n",
    "        # get corridor\n",
    "        corridor = get_distance_surface(\n",
    "                instance.shape[1:],\n",
    "                [path],\n",
    "                mode=\"dilation\",\n",
    "                n_dilate=dist[i]\n",
    "            )\n",
    "        corr = (corridor > 0).astype(int)\n",
    "    # plt.imshow(corr)\n",
    "    # plt.colorbar()\n",
    "    # plt.show()\n",
    "    # \n",
    "    config.graph.start_inds = (start_start/scales[i]).astype(int)\n",
    "    config.graph.dest_inds = (start_dest/scales[i]).astype(int)\n",
    "    config.graph.PYLON_DIST_MIN = PYLON_DIST_MIN/scales[i]\n",
    "    config.graph.PYLON_DIST_MAX = PYLON_DIST_MAX/scales[i]\n",
    "    print(config)\n",
    "    print(instance.shape)\n",
    "    print(corr.shape)\n",
    "    graph = graphs.ImplicitLG(instance, corr, verbose=0)\n",
    "    path, _, _ = graph.single_sp(**vars(config.graph))\n",
    "    \n",
    "    # plt.subplot(1, 6, i*2+1)\n",
    "    # plt.imshow(graph.instance)\n",
    "    # plt.axis(\"off\")\n",
    "\n",
    "    \n",
    "    #overlay_corridor = get_distance_surface(\n",
    "    #            instance.shape[1:],\n",
    "    #            [path],\n",
    "    #            mode=\"dilation\",\n",
    "    #            n_dilate=dist[i+1]\n",
    "    #        )\n",
    "    #\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    path = np.array(path)\n",
    "    plt.imshow(graph.instance)\n",
    "    # plt.imshow(overlay_corridor, alpha=0.3)\n",
    "    plt.plot(path[:,1], path[:,0], marker=\"o\", c=\"white\")\n",
    "    plt.axis(\"off\")\n",
    "        \n",
    "plt.savefig(\"../../figure/pipeline.png\")\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random pipeline figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_corridor = get_distance_surface(\n",
    "               instance.shape[1:],\n",
    "               [path],\n",
    "               mode=\"dilation\",\n",
    "               n_dilate=30\n",
    "           )\n",
    "overlay_corridor = (overlay_corridor-np.min(overlay_corridor))/(np.max(overlay_corridor)-np.min(overlay_corridor))\n",
    "arr = np.random.rand(*overlay_corridor.shape)\n",
    "over = (overlay_corridor) >arr\n",
    "random = np.sum(\n",
    "            np.moveaxis(random_instance, 0, -1) * config.graph.class_weights, axis=2\n",
    "        )\n",
    "inf_corr = np.absolute(1 - over).astype(float)\n",
    "inf_corr[inf_corr > 0] = np.inf\n",
    "\n",
    "graph = graphs.ImplicitLG(random_instance, np.ones(random_instance.shape[1:]), verbose=0)\n",
    "path_random, _, _ = graph.single_sp(**vars(config.graph))\n",
    "\n",
    "\n",
    "path_random = np.array(path_random)\n",
    "plt.imshow(random+inf_corr)\n",
    "# plt.imshow(overlay_corridor, alpha=0.3)\n",
    "plt.plot(path_random[:,1], path_random[:,0], marker=\"o\", c=\"red\", linewidth=5, markersize=15)\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"../../figure/random_pipeline.png\")\n",
    "\n",
    "plt.imshow(overlay_corridor)\n",
    "plt.colorbar()\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"../../figure/distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path cost figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from power_planner.utils.utils import normalize\n",
    "def plot_path_costs(\n",
    "    instance_in, path, edgecosts, path2, edgecosts2, class_names, out_path=None, buffer=1, strip = 50\n",
    "):\n",
    "    \"\"\"\n",
    "    Cost visualization: Plot one image for each cost class:\n",
    "    Arguments:\n",
    "        instance: n_classes x imgwidth x imgheight sized array\n",
    "        path: list or array of (x,y) coordinates\n",
    "        edgecosts: path length x n_classes array or list containing costs\n",
    "        class_names: n_classes list of names for plot titles\n",
    "        out_path: where to save\n",
    "        buffer: num pixels to color (for large images one pixel too small)\n",
    "    \"\"\"\n",
    "    add = 0.4\n",
    "    \n",
    "    print(instance_in.shape)\n",
    "    # wo_zero = instance_in[:, :, np.any(instance_in > 0, axis=(0,1))]\n",
    "    # instance = wo_zero[:, np.any(wo_zero > 0, axis=(0,2)), :]\n",
    "    instance = instance_in[:, strip:-strip, strip:-strip]\n",
    "    path = np.array(path)-strip \n",
    "    path2 = np.array(path2)-strip\n",
    "        \n",
    "    edgecosts = np.asarray(edgecosts)\n",
    "    edgecosts2 = np.asarray(edgecosts2)[:, 1:]\n",
    "    \n",
    "    print(\"out costs shape:\", edgecosts.shape)\n",
    "    n_crit = len(instance)\n",
    "    # exclude angle costs,\n",
    "    if n_crit < edgecosts.shape[1]:\n",
    "        edgecosts = edgecosts[:, 1:]\n",
    "\n",
    "    # iterate over cost classes to make subplots\n",
    "    plt.figure(figsize=(25, 15))\n",
    "    fig, axs = plt.subplots(1, n_crit+1, figsize=(25, 15), gridspec_kw={'width_ratios': [9.5 for _ in range(n_crit)] +[1]})\n",
    "    \n",
    "    for j in range(n_crit):\n",
    "        curr_costs = instance[j]\n",
    "        # from grey scale to colour channel image\n",
    "        expanded = np.expand_dims(curr_costs, axis=2)\n",
    "        expanded = np.tile(expanded, (1, 1, 3))\n",
    "        \n",
    "        # put values into visible range\n",
    "        min_c = np.min([np.min(edgecosts[:, j]), np.min(edgecosts2[:, j])])\n",
    "        max_c = np.max([np.max(edgecosts[1:-1:, j]), np.max(edgecosts2[1:-1, j])])\n",
    "        normed_env_costs = (edgecosts[:, j]-min_c)/(max_c-min_c)\n",
    "        normed2 = (edgecosts2[:, j]-min_c)/(max_c-min_c)\n",
    "        \n",
    "        \n",
    "        # colour nodes in path --> cross! --> first input path\n",
    "        for i, (x, y) in enumerate(path):\n",
    "            # colour red for high cost\n",
    "            expanded[x - buffer-1:x + buffer + 2, y-1:y+2] = [normed_env_costs[i]+add, 1 - normed_env_costs[i]+add,0.2]\n",
    "            expanded[x-1:x+2, y - buffer-1:y + buffer +2] = [normed_env_costs[i]+add, 1 - normed_env_costs[i]+add,0.2]\n",
    "            \n",
    "        # colour nodes in path --> circle --> second input path\n",
    "        for i, (x, y) in enumerate(path2):\n",
    "            # colour red for high cost\n",
    "            orig = expanded[x,y].copy()\n",
    "            expanded[x - buffer:x + buffer + 1, y - buffer:y + buffer +\n",
    "                     1] = [normed2[i]+add, 1 - normed2[i]+add, 0]\n",
    "            # expanded[x-buffer+2:x+buffer-1,y-buffer+2:y+buffer-1] = orig\n",
    "        # comment in next lines for stripping zero rows and columns\n",
    "        # wo_zero = expanded[:, np.any(curr_costs > 0, axis=0)]\n",
    "        # wo_zero = wo_zero[np.any(curr_costs > 0, axis=1), :]\n",
    "\n",
    "        # display\n",
    "        # ax = plt.subplot(1, n_crit+1, j + 1)\n",
    "        axs[j].imshow(np.swapaxes(expanded, 1, 0), origin=\"upper\")\n",
    "        axs[j].set_title(class_names[j], fontsize=30)\n",
    "        axs[j].axis(\"off\")\n",
    "        if j==0:\n",
    "            legend_elements = [mpl.lines.Line2D([0], [0],marker='+', markersize=30, c=[1,0,0], lw=0, label='Normal LCP'),\n",
    "               mpl.lines.Line2D([0], [0], marker='s', color='g', lw=0, label='Angle-cost LCP',\n",
    "                      c=[1,0,0], markersize=20)]\n",
    "            axs[j].legend(handles=legend_elements, loc='upper left', fontsize=30)        \n",
    "        \n",
    "    arr = np.zeros((39,2,3))\n",
    "    for i in range(39):\n",
    "        arr[i,:] = [i/39+0.4, 1-i/39+0.4, 0.2]\n",
    "    axs[j+1].imshow(arr, origin=\"lower\")\n",
    "    axs[j+1].yaxis.tick_right()\n",
    "    # axs[j+1].yaxis.label_right()\n",
    "    axs[j+1].set_yticklabels(np.around(np.arange(1.1,-0.1, 0.1),1))\n",
    "    axs[j+1].set_ylabel('Category-wise costs', fontsize=30)\n",
    "    axs[j+1].set_xticks([])\n",
    "    # cmap = plt.get_cmap(\"RdYlGn\")\n",
    "    # norm = mpl.colors.Normalize(vmin=0, vmax=1)\n",
    "    # cb1 = mpl.colorbar.ColorbarBase(axs[j+1], cmap=cmap,\n",
    "    #                                 norm=norm,\n",
    "    #                                 orientation='vertical')\n",
    "    # cb1.set_label('Category costs', fontsize=30) \n",
    "    \n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    # save image\n",
    "    if out_path is not None:\n",
    "        plt.savefig(out_path, bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impl_graph = graphs.ImplicitLG(belgium_inst, belgium_inst_corr, edge_instance=belgium_edge_inst)\n",
    "tic = time.time()\n",
    "belgium_config.graph.ANGLE_WEIGHT=0.3\n",
    "path_impl, path_costs_impl, cost_sum_impl =  impl_graph.single_sp(**vars(belgium_config.graph))\n",
    "print(time.time()-tic)\n",
    "# tune a bit:\n",
    "tuned_inst = belgium_inst.copy()\n",
    "for (i,j) in path_impl:\n",
    "    tuned_inst[:,i-5:i+5, j-5:j+5] =  tuned_inst[:,i-5:i+5, j-5:j+5]+0.3\n",
    "wg_graph = graphs.WeightedGraph(belgium_inst, belgium_inst_corr)\n",
    "tic = time.time()\n",
    "path_wg, path_costs_wg, cost_sum_wg = wg_graph.single_sp(**vars(belgium_config.graph))\n",
    "print(time.time()-tic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_path_costs(\n",
    "    belgium_inst * belgium_inst_corr,\n",
    "    path_wg,\n",
    "    path_costs_wg,\n",
    "    path_impl, path_costs_impl,\n",
    "    config.graph.layer_classes,\n",
    "    buffer=3, strip=50,\n",
    "    out_path=\"../../figure/path_costs.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find optimal colours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.zeros((10,20,3))\n",
    "for i in range(10):\n",
    "    arr[i,:] = [i/10+0.4, 1-i/10+0.4, 0.2]\n",
    "plt.imshow(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save paths (for evaluation plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_wg_scaled = np.asarray(path_wg) * 2\n",
    "path_impl_scaled = np.asarray(path_impl) * 2\n",
    "c_wg = np.sum([impl_graph.instance[i,j] for (i,j) in path_wg])\n",
    "c_impl = np.sum([impl_graph.instance[i,j] for (i,j) in path_impl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_paths.json\", \"w\") as outfile:\n",
    "    json.dump([path_wg_scaled.tolist(), path_impl_scaled.tolist()], outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random pipeline statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ground truth path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graphs.WeightedGraph(belgium_inst, belgium_inst_corr, verbose=False)\n",
    "tic = time.time()\n",
    "path_gt, path_costs_gt, cost_sum_gt = graph.single_sp(**vars(belgium_config.graph))\n",
    "edges_gt = graph.n_edges\n",
    "path_groundtruth = np.array(path_gt)\n",
    "print(\"number of edges\", edges_gt)\n",
    "time_gt = time.time()-tic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run multiple times to compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corr = np.ones(belgium_inst_corr.shape)\n",
    "test_corr[:50,:] = 0\n",
    "test_corr[:,:50] = 0\n",
    "test_corr[:,-50:] = 0\n",
    "test_corr[-50:,:] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test code before transformed to script: automatically compute corridor width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cfg = belgium_config.graph\n",
    "PIPE1 = [(0.8, 100), (0.5, 50), (0, 0)]\n",
    "MAX_EDGES = 1000000\n",
    "D1 = 100\n",
    "D2 = 0\n",
    "random = 1\n",
    "\n",
    "PIPE2 = [(MAX_EDGES, D1), (MAX_EDGES, 0)] # D2), (MAX_EDGES, 0)]\n",
    "PIPE2 = [(3,50), (2,20), (1,0)] # [(0.9, 50), (0.75, 20), (0,0)] # [1384653, 1426099, 1218601] #\n",
    "\n",
    "max_nr_edges = []\n",
    "times_pipeline = []\n",
    "correct = []\n",
    "output = []\n",
    "\n",
    "if random:\n",
    "    nr_iters = 1 # 00\n",
    "    mult_factor = 10\n",
    "    graphclass = graphs.RandomWeightedGraph\n",
    "else:\n",
    "    nr_iters = 1\n",
    "    mult_factor = 13\n",
    "    graphclass = graphs.WeightedGraph\n",
    "remain_edges_factor = 1/(PIPE2[0][0])**2\n",
    "\n",
    "print(\"predicted edges after first:\", remain_edges_factor*edges_gt)\n",
    "\n",
    "# COMPUTE STATISTICS\n",
    "for _ in range(nr_iters):\n",
    "\n",
    "    graph = graphclass(belgium_inst, test_corr, verbose=False) # belgium_inst_corr\n",
    "    # set shift necessary in case of random graph automatic probability estimation by edge bound\n",
    "    graph.set_shift(\n",
    "            cfg.start_inds, cfg.dest_inds,\n",
    "            **vars(cfg)\n",
    "        )\n",
    "\n",
    "    # in each pipeline the corridar is initially everything\n",
    "    corridor = np.ones(belgium_inst_corr.shape) * 0.5\n",
    "    edge_numbers = list()\n",
    "\n",
    "    tic = time.time()\n",
    "\n",
    "    for pipe,(factor, dist) in enumerate(PIPE2):\n",
    "        if random:\n",
    "            factor = 1-(1/factor**2)\n",
    "            print(factor)\n",
    "        graph.set_corridor(corridor, cfg.start_inds, cfg.dest_inds, factor_or_n_edges=factor) # , mode=\"squared\")\n",
    "        \n",
    "        # prob_arr = np.random.rand(*graph.corridor.shape)\n",
    "        # prob_arr = (graph.corridor > prob_arr).astype(int)\n",
    "        # plt.imshow(prob_arr)\n",
    "        # plt.show()\n",
    "        \n",
    "        path_wg = []\n",
    "        while len(path_wg)==0:\n",
    "            path_wg, path_costs_wg, cost_sum_wg = graph.single_sp(**vars(cfg))\n",
    "            graph.remove_vertices(corridor)\n",
    "        print(\"actual number edges\", graph.n_edges)\n",
    "\n",
    "        if dist>0:\n",
    "            corridor = get_distance_surface(\n",
    "                    graph.hard_constraints.shape,\n",
    "                    [path_wg],\n",
    "                    mode=\"dilation\",\n",
    "                    n_dilate=10 # dist\n",
    "                )\n",
    "            # estimated edges are pixels times neighbors divided by resolution squared\n",
    "            estimated_edges_10 = len(np.where(corridor>0)[0])*len(graph.shifts)/((PIPE2[pipe+1][0])**2)\n",
    "            print(\"estimated with distance 10:\", estimated_edges_10)\n",
    "            now_dist = mult_factor * graph.n_edges / estimated_edges_10 \n",
    "            # print(\"reduce corridor:\", dist) \n",
    "            corridor = get_distance_surface(\n",
    "                    graph.hard_constraints.shape,\n",
    "                    [path_wg],\n",
    "                    mode=\"dilation\",\n",
    "                    n_dilate=int(np.ceil(now_dist))\n",
    "                )\n",
    "            print(\"estimated with distance \", int(np.ceil(now_dist)), len(np.where(corridor>0)[0])*len(graph.shifts)/((PIPE2[pipe+1][0])**2))\n",
    "        graph.remove_vertices(corridor)\n",
    "        edge_numbers.append(graph.n_edges)\n",
    "        # plt.imshow(graph.corridor)\n",
    "        # plt.colorbar()\n",
    "        # plt.show()\n",
    "\n",
    "    time_pipeline = time.time()-tic\n",
    "    \n",
    "    times_pipeline.append(time_pipeline)\n",
    "    max_nr_edges.append(np.max(edge_numbers))\n",
    "    # correct.append(np.all(np.array(path_wg) == np.asarray(path_gt)))\n",
    "    output.append([path_wg, path_costs_wg, cost_sum_wg])\n",
    "    \n",
    "    # print(np.max(edge_numbers), \"equal gt?\", np.all(np.array(path_wg) == np.asarray(path_gt)))\n",
    "\n",
    "    # idee: evaluate per pylon increase in cost\n",
    "    # log dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auswertung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX_EDGES = 5000000\n",
    "LEN_PIPE = len(PIPE2)\n",
    "\n",
    "with open(f\"random_results_{MAX_EDGES}_{LEN_PIPE}_{d1}_{d2}.dat\", \"wb\") as outfile:\n",
    "    pickle.dump((output, max_nr_edges, times_pipeline, correct), outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from power_planner.utils.utils_ksp import KspUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EDGES = 1000000\n",
    "LEN_PIPE = 2\n",
    "d1 = 100\n",
    "d2 = 50\n",
    "with open(\"../../outputs/random_results_[(4, 50), (1, 0), (1, 0)]\", \"rb\") as outfile:\n",
    "    (output, max_nr_edges, times_pipeline, correct) = pickle.load(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_factor = np.mean(max_nr_edges) / edges_gt\n",
    "print(\"Reducing the number of edges by a factor of \", edge_factor)\n",
    "print(\"Using time \", np.mean(times_pipeline), \"compared to\", time_gt)\n",
    "percent_correct = np.around(np.sum(np.array(correct).astype(int))/ len(correct), 2)\n",
    "print(\"Percentage correct:\", percent_correct)\n",
    "\n",
    "unique_path_set = []\n",
    "unique_costs = []\n",
    "paths_computed = [np.array(o[0]) for o in output]\n",
    "for (new_path, _, cost) in output:\n",
    "    already = [len(path)==len(new_path) and np.all(path==new_path) for path in unique_path_set]\n",
    "    if not np.any(already):\n",
    "        unique_path_set.append(new_path)\n",
    "        unique_costs.append(cost)\n",
    "print(\"Number of unique produced paths:\", len(unique_path_set))\n",
    "intersection_w_gt = 1-np.mean([np.around(KspUtils.path_distance(path_gt, p2),2) for p2 in paths_computed])\n",
    "print(\"Intersections with ground truth\", intersection_w_gt)\n",
    "eucl_w_gt = np.mean([np.around(KspUtils.path_distance(path_gt, p2, \"eucl_mean\"),2) for p2 in paths_computed])\n",
    "print(\"Mean eucledian distance of paths and ground truth\", eucl_w_gt)\n",
    "print(\"New costs\", np.mean(unique_costs), \"vs cost gt:\", cost_sum_gt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_list = np.around(np.array([np.mean(times_pipeline), edge_factor, percent_correct, np.mean(unique_costs), np.std(unique_costs), intersection_w_gt, eucl_w_gt]), 2).tolist()\n",
    "list_of_elem = [f\"{MAX_EDGES}_{LEN_PIPE}_{d1}_{d2}\"] + res_list\n",
    "with open(\"random_results.csv\", 'a+', newline='') as write_obj:\n",
    "    # Create a writer object from csv module\n",
    "    csv_writer = writer(write_obj)\n",
    "    # Add contents of list as last row in the csv file\n",
    "    csv_writer.writerow(list_of_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_arr = np.array([\n",
    "    [1000000, 3, 100, 50, 15.5, 0, 0.08, 11.26],\n",
    "    [1000000, 3, 100, 50, 15.5, 0, 0.08, 11.26]\n",
    "])\n",
    "result_table = pd.DataFrame(res_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline comparison: tests before making script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct instance where infinity regions have high cost --> only necessary for belgium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_inst_corr = np.ones(belgium_inst_corr.shape)\n",
    "tuned_inst = belgium_inst.copy()\n",
    "inverted = np.absolute(belgium_inst_corr-1).astype(\"bool\")\n",
    "tuned_inst[:, inverted] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run first time: with 8-neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_bl = graphs.ImplicitLG(tuned_inst, tuned_inst_corr, verbose=True)\n",
    "# set shift necessary in case of random graph automatic probability estimation by edge bound\n",
    "# graph_bl.set_shift(cfg.start_inds, cfg.dest_inds, pylon_dist_min=1,\n",
    "#         pylon_dist_max=1.5,\n",
    "#         max_angle=cfg.max_angle,\n",
    "#         max_angle_lg=cfg.max_angle_lg,)\n",
    "cfg.pylon_dist_min = 1\n",
    "cfg.pylon_dist_max = 1.5\n",
    "cfg.edge_weight = 0\n",
    "path_raster, path_costs_raster, _ = graph_bl.single_sp(**vars(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_raster = np.array(path_raster)\n",
    "plt.plot(path_raster[:,1], path_raster[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct corridor from the raster path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylon_spotting_corr = np.zeros(belgium_inst_corr.shape)\n",
    "for (i,j) in path_raster:\n",
    "    if belgium_inst_corr[i,j]< np.inf:\n",
    "        pylon_spotting_corr[i,j] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pylon spotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_pylon_spotting = graphs.ImplicitLG(belgium_inst, pylon_spotting_corr, edge_instance=belgium_edge_inst, verbose=True)\n",
    "cfg.pylon_dist_min = 7.5\n",
    "cfg.pylon_dist_max = 12.5\n",
    "path_bl,path_cost_bl, cost_sum_bl = graph_pylon_spotting.single_sp(**vars(cfg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corresponding GT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_gt = graphs.ImplicitLG(belgium_inst, belgium_inst_corr, edge_instance=belgium_edge_inst, verbose=True)\n",
    "path_gt,path_cost_gt, cost_sum_gt = graph_gt.single_sp(**vars(cfg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_bl = np.array(path_bl)\n",
    "path_gt = np.array(path_gt)\n",
    "plt.plot(path_bl[:,1], path_bl[:,0])\n",
    "plt.plot(path_gt[:,1], path_gt[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"per pylon cost \", cost_sum_bl/len(path_bl), cost_sum_gt/len(path_groundtruth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.array(path_costs_gt) * np.array(cfg.class_weights)), np.sum(np.array(path_cost_bl)[:, 1:] * np.array(cfg.class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belgium_config.graph.layer_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auswertung baseline analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_results = pd.read_csv(\"../../figure/baseline_results_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_results[\"ID\"] = [\"Baseline\" if i%2==0 else \"Ours\" for i in range(len(bl_results))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bl_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped_res = bl_results.groupby([\"instance\", \"ID\"]).agg({\"overall time\":\"mean\", \"space required for edges\":\"mean\", \"angle cost\": \"mean\", \n",
    "                                            \"weighted sum of costs\":\"mean\",\n",
    "                                           \"mean distance\": \"max\", \"max distance\":\"max\"})\n",
    "grouped_res = np.around(grouped_res, 1)\n",
    "grouped_res = grouped_res.rename(columns={\"overall time\": \"Time (seconds)\", \"angle cost\": \"Angle cost\", \n",
    "                           \"weighted sum of costs\": \"Resistance\", \"mean distance\": \"Average distance from baseline (in meter)\",\n",
    "                          \"max distance\":\"Maximum distance from baseline (in meter)\", \"space required for edges\":\"Number of edges\"})\n",
    "grouped_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = bl_results.groupby([\"graph\", \"ID\"]).agg({\"overall time\":\"mean\", \"space required for edges\":\"mean\", \"angle cost\": \"mean\", \n",
    "                                            \"weighted sum of costs\":\"mean\",\n",
    "                                           \"mean distance\": \"max\", \"max distance\":\"max\"})\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot showing how angle cost change by different weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=\"angle weight\", y=\"angle cost\", hue=\"ID\", data=bl_results)\n",
    "ax.set_xlabel(\"Angle weighting\", fontsize=15)\n",
    "ax.set_ylabel(\"Angle costs\", fontsize=15)\n",
    "ax.legend(fontsize=15)\n",
    "plt.savefig(\"../../figure/bar_angle_baseline.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auswertung random analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_columns_distfactor(res_df):\n",
    "    pipeline_out = np.zeros((len(res_df), 4))\n",
    "    # e1, e2, e3, d1,d2 = [],[],[],[],[]\n",
    "    for i, row in res_df.iterrows():\n",
    "        pipe_id = (row[\"ID\"]).split(\"_\")\n",
    "        if len(pipe_id)>1:\n",
    "            pipe_id = pipe_id[1]\n",
    "        else:\n",
    "            pipe_id = pipe_id[0]\n",
    "        id_split = pipe_id[2:-2].split(\"), (\")\n",
    "        e1_elem, d1_elem = tuple(id_split[0].split(\", \"))\n",
    "        e2_elem, d2_elem = tuple(id_split[1].split(\", \"))\n",
    "        pipeline_out[i] = [float(e1_elem), int(d1_elem), float(e2_elem), int(d2_elem)]\n",
    "        # e1.append(int(e1_elem))\n",
    "        # e2.append(d2_elem)\n",
    "    col_name = [\"e1\", \"d1\", \"e2\", \"d2\"]\n",
    "    for i in range(4):\n",
    "        res_df[col_name[i]] = pipeline_out[:,i]\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = pd.read_csv(\"../../outputs/random_results_2908.csv\") # random_results_prior.csv\")# [:-75] #\n",
    "deterministic = pd.read_csv(\"../../outputs/nonrandom_pipelines.csv\") # andom_results_prior.csv\") # \n",
    "prior = pd.read_csv(\"../../outputs/random_results_prior.csv\") [75:]\n",
    "# random = res_df[res_df[\"ID\"].str.contains(\"0000\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_df = pd.read_csv(\"../../outputs/random_results_0109.csv\")\n",
    "deterministic = in_df[~in_df[\"ID\"].str.contains(\"\\[0.\")]\n",
    "random = in_df[in_df[\"ID\"].str.contains(\"\\[0.\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_df = pd.read_csv(\"../../outputs/random_results_final_0209.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIPELINE LENGTH\n",
    "pipeline_length = np.array([len(val.split(\",\")) for val in in_df[\"ID\"].values])\n",
    "np.unique(pipeline_length)\n",
    "random = in_df[pipeline_length==2]\n",
    "deterministic = in_df[pipeline_length==4]\n",
    "prior = in_df[pipeline_length==6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = in_df[in_df[\"prior\"]==\"no prior\"]\n",
    "prior = in_df[in_df[\"prior\"]==\"prior\"]\n",
    "deterministic = in_df[in_df[\"prior\"]==\"simple downsampling\"]\n",
    "watershed = in_df[in_df[\"prior\"]==\"watershed\"]\n",
    "print(len(random), len(prior), len(deterministic), len(watershed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random = add_columns_distfactor(random)\n",
    "# deterministic = add_columns_distfactor(deterministic)\n",
    "# prior = add_columns_distfactor(prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "random = in_df[in_df[\"ID\"].str.contains(\"\\[0.\")]\n",
    "# pearsonr(np.arange(30), [0 for _ in range(15)] + [1 for _ in range(15)])\n",
    "pearsonr(random[\"time\"], random[\"average intersection with gt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_x_axis = \"remaining edges\" # \"time\" # \n",
    "plot_y_axis = \"average intersection with gt\" # \"average costs\" # \" percent correct\" #  \n",
    "# ' average eucledian distance from GT' #  #  # \n",
    "markers = [\"o\", \"x\", \"+\"]\n",
    "plt.figure(figsize=(11,7))\n",
    "for ma,inst in zip(markers, [\"belgium\", \"de\", \"ch\"]): # , \"ch\"]):\n",
    "    random_inst = random[random[\"instance\"]==inst]\n",
    "    deterministic_inst = deterministic[deterministic[\"instance\"]==inst]\n",
    "    prior_inst = prior[prior[\"instance\"]==inst]\n",
    "    watershed_inst = watershed[watershed[\"instance\"]==inst]\n",
    "    # random_res = random_de[random_de[\"e1\"]>10]\n",
    "    plt.scatter(watershed_inst[plot_x_axis], watershed_inst[plot_y_axis], marker=ma, c=\"orange\", s=100, alpha=0.5)\n",
    "    # static_res = all_dfs # random_de[random_de[\"e1\"]<10]\n",
    "    plt.scatter(deterministic_inst[plot_x_axis], deterministic_inst[plot_y_axis], marker=ma, c=\"red\", s=100, alpha=0.5)\n",
    "    plt.scatter(random_inst[plot_x_axis], random_inst[plot_y_axis], marker=ma, c=\"blue\", s=100, alpha=0.5)\n",
    "    plt.scatter(prior_inst[plot_x_axis], prior_inst[plot_y_axis], marker=ma, c=\"green\", alpha=0.5, s=100)\n",
    "legend_elements = [Line2D([0], [0], color='b', marker='o', lw=10, label='Random Pipeline'),\n",
    "                   Line2D([0], [0], color='g', marker='o', lw=10, label='Random with prior'),\n",
    "                   Line2D([0], [0], marker='o', color='r', lw=10, label='Deterministic Pipeline'),\n",
    "                   Line2D([0], [0], color='orange', marker='o', lw=10, label='Deterministic with watershed'),\n",
    "                  Line2D([0], [0], marker='o', markersize=10, color='black', lw=0, label='Instance 1'),\n",
    "                  Line2D([0], [0], marker='x', markersize=10, color='black', lw=0, label='Instance 2'),\n",
    "                  Line2D([0], [0], marker='+', markersize=10, color='black', lw=0, label='Instance 3')]\n",
    "if plot_y_axis==\"average intersection with gt\":\n",
    "    plt.ylim(0,1.1)\n",
    "    ylabel = \"Average IoU with LCP\"\n",
    "    name=\"intersection\"\n",
    "elif plot_y_axis==\"average costs\":\n",
    "    # legend=plt.legend(handles=legend_elements, loc='lower left', fontsize=15, framealpha=0)\n",
    "    # legend.get_frame().set_linewidth(3)\n",
    "    name=\"costs\"\n",
    "    ylabel = \"Average path costs\"\n",
    "elif plot_y_axis==\" percent correct\":\n",
    "    legend=plt.legend(handles=legend_elements, loc='center right', fontsize=15)\n",
    "    legend.get_frame().set_linewidth(3)\n",
    "    name=\"percent_correct\"\n",
    "    ylabel = \"Percent correct (LCP found)\"\n",
    "if plot_x_axis==\"remaining edges\":\n",
    "    plt.xlim(0,0.4)\n",
    "    plt.xlabel(\"Ratio of remaining edges\", fontsize=22, weight=\"bold\")\n",
    "else:\n",
    "    # plt.xlim(0,26)\n",
    "    name=name+\"_time\"\n",
    "    plt.xlabel(\"Runtime (in seconds)\", fontsize=22, weight=\"bold\") \n",
    "    # plt.xscale(\"log\")\n",
    "plt.ylabel(ylabel, fontsize=22, weight=\"bold\")\n",
    "# plt.savefig(\"../../figure/\"+name+\".pdf\", bbox_inches=\"tight\", pad_inches=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_choice = [2,3,4,5]\n",
    "for factor in [0.1, 0.15, 0.2, 0.25]:\n",
    "    best_factor = factor_choice[np.argmin([np.abs(1/f**2 - factor) for f in factor_choice])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backup code\n",
    "PIPELINES = []\n",
    "for factor1 in [2, 3, 4, 5]:\n",
    "    for factor2 in [1, 2]:\n",
    "        if factor1 <= factor2:\n",
    "            continue\n",
    "        if factor2 == 1:\n",
    "            PIPELINES.append([factor1, factor2])\n",
    "        else:\n",
    "            PIPELINES.append([factor1, factor2, 1])\n",
    "print(\"PIPELINES:\", PIPELINES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge serveral csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for infile in [\"2708\", \"debech\",\"50\", \"cluster_backup\"]:\n",
    "    dfs.append(pd.read_csv(\"../../outputs/random_results_\"+infile+\".csv\"))\n",
    "all_dfs = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = all_dfs[all_dfs[\"ID\"].str.contains(\"(1, 0)\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs.to_csv(\"../../outputs/nonrandom_pipelines.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_part = pd.read_csv(\"../../outputs/random_results_0109.csv\")\n",
    "second_part = pd.read_csv(\"../../outputs/random_final_0209.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_part[\"prior\"] = \"simple downsampling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_part.loc[first_part[\"ID\"].str.contains(\"\\[0.\"), \"prior\"] = \"no prior\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = pd.concat([first_part, second_part])\n",
    "all_dfs.to_csv(\"random_results_final_0209.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diverse Ksp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"compare_diverse_thesis_belgium.dat\", \"rb\") as outfile:\n",
    "    all_ksps = pickle.load(outfile)\n",
    "path_csv = pd.read_csv(\"compare_diverse_thesis_belgium.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_k_sp(ksp, inst, out_path=None):\n",
    "    \"\"\"\n",
    "    Plot k shortest paths on the instance\n",
    "    Arguments:\n",
    "        ksp: list of infos for the k shortest path: for each path, the first\n",
    "            entry is the path itself, the second the costs array, the third\n",
    "            the cost sum\n",
    "        inst: instance to plot on\n",
    "    \"\"\"\n",
    "    # get relevant information\n",
    "    costs = [k[2] for k in ksp]\n",
    "    paths = [k[0] for k in ksp]\n",
    "\n",
    "    # plot main image (cost surface)\n",
    "    plt.figure(figsize=(10, 20))\n",
    "    plt.imshow(np.swapaxes(inst, 1, 0))\n",
    "    # iterate over k shortest paths\n",
    "    for i, path in enumerate(paths):\n",
    "        path = np.asarray(path)\n",
    "        plt.scatter(\n",
    "            path[:, 0], path[:, 1], label=str(round(costs[i], 2)), s=50\n",
    "        )\n",
    "    # plot and save\n",
    "    leg = plt.legend(fontsize=15)\n",
    "    leg.set_title('Costs', prop={'size': 15})\n",
    "    # plt.title(out_path.split(\"/\")[1], fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### final code to plot all paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cutoff = 55\n",
    "disp_inst = np.swapaxes(impl_graph.instance, 1,0)[cutoff:-cutoff, cutoff:-cutoff]\n",
    "for name, df_grouped in path_csv.groupby(\"name\"):\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    l = len(df_grouped)\n",
    "    sorted_ind = np.array(list(df_grouped.index))[np.argsort(df_grouped[\"threshold\"])]\n",
    "    for i, ind in enumerate(sorted_ind):\n",
    "        plt.subplot(1,l+1, i+1)\n",
    "        plt.imshow(disp_inst)\n",
    "        \n",
    "        # preparation\n",
    "        ksp = all_ksps[ind]\n",
    "        costs = [k[2] for k in ksp]\n",
    "        paths = [k[0] for k in ksp]\n",
    "\n",
    "        # plot main image (cost surface)\n",
    "        # iterate over k shortest paths\n",
    "        for i, path in enumerate(reversed(paths)):\n",
    "            path = np.asarray(path)-cutoff\n",
    "            plt.scatter(\n",
    "                path[:, 0], path[:, 1], label=str(round(costs[i], 2)), s=50\n",
    "            )\n",
    "        # plot and save\n",
    "        # leg = plt.legend(fontsize=15)\n",
    "        # leg.set_title('Costs', prop={'size': 15})\n",
    "    \n",
    "        plt.axis(\"off\")\n",
    "        plt.title(df_grouped.loc[ind, \"threshold\"], fontsize=20)\n",
    "    # fig.suptitle(name, fontsize=20)\n",
    "    fig.tight_layout()\n",
    "    # fig.subplots_adjust(top=0.88)\n",
    "    plt.savefig(\"../../figure/ksp_\"+name+\".pdf\", bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ksp time plot (runtime by diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib \n",
    "matplotlib.rc('xtick', labelsize=20) \n",
    "matplotlib.rc('ytick', labelsize=20)\n",
    "\n",
    "font = {'size'   : 20}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksp_res = pd.read_csv(\"compare_diverse_thesis_belgium2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for name, grouped in ksp_res.groupby(\"name\"):\n",
    "    if \"set\" in name:\n",
    "        sorted_grouped = grouped.sort_values(by=\"threshold\", ascending=False)\n",
    "    else:\n",
    "        sorted_grouped = grouped.sort_values(by=\"threshold\")\n",
    "    if \"dispersion\" in name: # or \"mean\" in name:\n",
    "        print(grouped[\"times\"].values)\n",
    "        continue\n",
    "    plt.plot(np.arange(len(grouped))/(len(grouped)-1), sorted_grouped[\"times\"].values, label=name, linewidth=3)\n",
    "plt.legend()\n",
    "plt.yscale(\"log\")\n",
    "plt.xticks([])\n",
    "plt.xlabel(\"Diversity threshold\", weight=\"bold\")\n",
    "plt.ylabel(\"Runtime (log scale)\", weight=\"bold\")\n",
    "plt.savefig(\"../../figure/ksp_times.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph comparison auswertung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_comp = pd.read_csv(\"../../outputs/graph_comp_0109.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grouped_res = graph_comp.groupby([\"instance\", \"resolution\", \"graph\"]).agg({\"overall time\":\"mean\", \"space required for edges\":\"mean\", \"angle cost\": \"mean\", \n",
    "                                            \"weighted sum of costs\":\"mean\"})\n",
    "grouped_res = np.around(grouped_res, 1)\n",
    "grouped_res = grouped_res.rename(index={\"belgium\":\"Instance 1\", \"ch\":\"Instance 3\", \"de\":\"Instance 2\"}, columns={\"overall time\": \"Time (seconds)\", \"graph\":\"Shortest path implementation\", \"angle cost\": \"Angle cost\", \n",
    "                           \"weighted sum of costs\": \"Resistance\", \"space required for edges\":\"Space required for graph (~number of edges)\"})\n",
    "grouped_res = grouped_res.sort_values(by=[\"instance\", \"resolution\"])\n",
    "grouped_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_res.to_csv(\"../../figure/graph_comp.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resetted = grouped_res.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "ax = sns.barplot(x=\"instance\", y=\"Angle cost\", hue=\"graph\", data=resetted)\n",
    "ax.set_ylabel(\"Angle cost\", weight=\"bold\", fontsize=25)\n",
    "ax.set_xlabel(\"Instance\", weight=\"bold\", fontsize=25)\n",
    "ax.set_xticklabels([\"1\",\"2\",\"3\"])\n",
    "# ax.set_xlabel(\"\")\n",
    "plt.savefig(\"../../figure/graphcomp_anglecost.pdf\", bbox_inches=\"tight\", pad_inches=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "ax = sns.barplot(x=\"resolution\", y=\"Space required for graph (~number of edges)\", hue=\"graph\", data=resetted, ci=None)\n",
    "ax.set_ylabel(\"Number of edges\", weight=\"bold\", fontsize=25)\n",
    "ax.set_xlabel(\"Resolution (in m)\", weight=\"bold\", fontsize=25)\n",
    "plt.yscale(\"log\")\n",
    "plt.legend([],[], frameon=False)\n",
    "plt.savefig(\"../../figure/graphcomp_nedges.pdf\", bbox_inches=\"tight\", pad_inches=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline evaluation 2: pipeline vs direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipes_df = pd.read_csv(\"../../outputs/pipeline_eval.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipes_df_test = pipes_df[pipes_df[\"graph\"]==\"Implicit line graph\"]\n",
    "plt.figure(figsize=(10,6))\n",
    "ax = sns.barplot(x=\"instance\", y=\"overall time\", hue=\"ID\", data=pipes_df, ci=None) # space required for edges\n",
    "ax.set_ylabel(\"Runtime (s)\", weight=\"bold\", fontsize=25) # Max. number of edges\n",
    "ax.set_xlabel(\"Instance (resolution)\", weight=\"bold\", fontsize=25)\n",
    "# plt.yscale(\"log\")\n",
    "ax.set_xticklabels([\"1 (10m)\",\"2 (20m)\",\"3 (20m)\"])\n",
    "plt.legend(title=\"Pipeline\", ncol=2)\n",
    "# plt.savefig(\"../../figure/pipeline_eval_time.pdf\", bbox_inches=\"tight\", pad_inches=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR TESTING\n",
    "full = pipes_df[pipes_df[\"ID\"]==\"[1]\"]\n",
    "less = pipes_df[pipes_df[\"ID\"]!=\"[1]\"]\n",
    "full_normal = full[full[\"graph\"]==\"Normal graph\"]\n",
    "full_impl = full[full[\"graph\"]==\"Implicit graph\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped_res = pipes_df.groupby([\"instance\", \"graph\", \"ID\"]).agg({\"overall time\":\"mean\", \"space required for edges\":\"mean\", \"angle cost\": \"mean\", \n",
    "                                            \"weighted sum of costs\":\"mean\"})\n",
    "grouped_res = np.around(grouped_res, 1)\n",
    "grouped_res = grouped_res.rename(index={\"belgium\":\"Instance 1\", \"ch\":\"Instance 3\", \"de\":\"Instance 2\"})\n",
    "            #, columns={\"overall time\": \"Time (seconds)\", \"graph\":\"Shortest path implementation\", \"angle cost\": \"Angle cost\", \n",
    "                          # \"weighted sum of costs\": \"Resistance\", \"space required for edges\":\"Space required for graph (~number of edges)\"})\n",
    "grouped_res = grouped_res.sort_values(by=[\"instance\", \"graph\"])\n",
    "grouped_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10760412 / 139824516"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_grouped = grouped_res.groupby([\"instance\", \"graph\"]).transform(lambda x: (x/x.iat[0])) # , axis=0) # map(x[\"angle cost\"][0], x)) #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_normed = normalized_grouped.groupby(\"ID\").agg({\"overall time\":[\"mean\", \"std\"], \"weighted sum of costs\":[\"mean\", \"std\"], \n",
    "                                                   \"space required for edges\":[\"mean\", \"std\"]})\n",
    "agg_normed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barWidth = 0.25\n",
    "# set height of bar\n",
    "columns = [\"overall time\", \"weighted sum of costs\", \"space required for edges\"]\n",
    "names = [\"Runtime (s)\", \"Cost\", \"Max. number of edges\"]\n",
    "colours = [\"blue\", \"red\", \"green\"]\n",
    "r1 = np.arange(len(agg_normed)).astype(\"float\")\n",
    "plt.figure(figsize=(10,6))\n",
    "i = 0\n",
    "for colour, column, name in zip(colours, columns, names):\n",
    "    # Make the plot\n",
    "    values = agg_normed[column, \"mean\"]\n",
    "    plt.bar(r1+i*barWidth, values, color=colour, width=barWidth, edgecolor='white', label=name, yerr=agg_normed[column, \"std\"])\n",
    "    i+=1\n",
    "plt.xlabel('Pipeline', fontweight='bold')\n",
    "plt.xticks([r + barWidth for r in range(len(agg_normed))], agg_normed.index)\n",
    "plt.ylabel(\"Percent of optimal path\", weight=\"bold\")\n",
    "plt.ylim(0,1.3)\n",
    "# Create legend & Show graphic\n",
    "plt.legend(ncol=3, fontsize=15, loc=\"upper center\")\n",
    "plt.savefig(\"../../figure/pipeline_eval_allinone.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
